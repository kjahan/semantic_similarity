{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "img_auto_encoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbmHTVzZgxyL0RrB2UD+na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjahan/semantic_similarity/blob/image_encoder/examples/colab/img_auto_encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXuhobmin18J"
      },
      "source": [
        "## Image auto encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uejaf39rn8ko"
      },
      "source": [
        "## Install packages\n",
        "\n",
        "Ref: https://medium.com/analytics-vidhya/image-similarity-model-6b89a22e2f1a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU97rGfpoJn4"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp8wObwPpD6t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7GSaVotpEDh",
        "outputId": "21a2d2ff-c698-4817-f3cf-87e5613573d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxlneCqmuKy"
      },
      "source": [
        "DATA_PATH = '../content/gdrive/MyDrive/dataset/dataset'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHX53_poQc9"
      },
      "source": [
        "## Split dataset to Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mACAJMJmoKFw",
        "outputId": "9f95bed8-b4d5-46cb-96d4-bb938b53a80c"
      },
      "source": [
        "# Extracting image paths\n",
        "file_path = os.listdir(DATA_PATH)\n",
        "print(len(file_path))\n",
        "\n",
        "train_files, test_files = train_test_split(file_path, test_size = 0.15)\n",
        "\n",
        "print(\"Number of Training Images:\",len(train_files))\n",
        "print(\"Number of Test Images: \",len(test_files))\n",
        "train_files = pd.DataFrame(train_files, columns=['filepath'])\n",
        "test_files = pd.DataFrame(test_files, columns=['filepath'])\n",
        "\n",
        "# converting into .csv file for future reference.\n",
        "train_files.to_csv('train_file.csv')\n",
        "test_files.to_csv('test_file.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4788\n",
            "Number of Training Images: 4069\n",
            "Number of Test Images:  719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkSlg_o2lkOm"
      },
      "source": [
        "## Read images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Kqw_mZoVT6"
      },
      "source": [
        "def image2array(file_array, data_path):\n",
        "    \"\"\"\n",
        "    Reading and Converting images into numpy array by taking path of images.\n",
        "    Arguments:\n",
        "    file_array - (list) - list of file(path) names\n",
        "    Returns:\n",
        "    A numpy array of images. (np.ndarray)\n",
        "    \"\"\"\n",
        "\n",
        "    image_array = []\n",
        "    for fn in tqdm(file_array):\n",
        "        img = cv2.imread(data_path + '/' + fn)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (224,224))\n",
        "        image_array.append(np.array(img))\n",
        "\n",
        "    image_array = np.array(image_array)\n",
        "    image_array = image_array.reshape(image_array.shape[0], 224, 224, 3)\n",
        "    image_array = image_array.astype('float32')\n",
        "    image_array /= 255\n",
        "\n",
        "    return np.array(image_array)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj9arZKhlpPU",
        "outputId": "c0e75707-6e4c-47cc-a86b-819a18ac38c3"
      },
      "source": [
        "train_data = image2array(train_files['filepath'].tolist()[:100], DATA_PATH)\n",
        "print(\"Length of training dataset:\",train_data.shape)\n",
        "test_data = image2array(test_files['filepath'].tolist()[:10], DATA_PATH)\n",
        "print(\"Length of test dataset:\",test_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 103.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 125.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Length of training dataset: (100, 224, 224, 3)\n",
            "Length of test dataset: (10, 224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDmZDfHynLdi"
      },
      "source": [
        "## Construct model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjjwFZ2nMAP"
      },
      "source": [
        "def encoder_decoder_model():\n",
        "\n",
        "    \"\"\"\n",
        "    Used to build Convolutional Autoencoder model architecture to get compressed image data which is easier to process.\n",
        "    Returns:\n",
        "    Auto encoder model\n",
        "    \"\"\"\n",
        "\n",
        "    #Encoder \n",
        "    model = Sequential(name='Convolutional_AutoEncoder_Model')\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(224, 224, 3),padding='same', name='Encoding_Conv2D_1'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_1'))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),strides=1,kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu',padding='same', name='Encoding_Conv2D_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_2'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_3'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_3'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_4'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,padding='valid', name='Encoding_MaxPooling2D_4'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='Encoding_Conv2D_5'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "    #Decoder\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu', padding='same', name='Decoding_Conv2D_1'))\n",
        "    model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_1'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same', name='Decoding_Conv2D_2'))\n",
        "    model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_2'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same',name='Decoding_Conv2D_3'))\n",
        "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_3'))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_4'))\n",
        "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_4'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_5'))\n",
        "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_5'))\n",
        "    model.add(Conv2D(3, kernel_size=(3, 3), padding='same',activation='sigmoid',name='Decoding_Output'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCAqUkNqnbg4",
        "outputId": "ac0ae5d1-6f0f-4bc5-d393-94cefc8ee3b1"
      },
      "source": [
        "model = encoder_decoder_model()\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Convolutional_AutoEncoder_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Encoding_Conv2D_1 (Conv2D)   (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "Encoding_MaxPooling2D_1 (Max (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "Encoding_Conv2D_2 (Conv2D)   (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "Encoding_MaxPooling2D_2 (Max (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "Encoding_Conv2D_3 (Conv2D)   (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "Encoding_MaxPooling2D_3 (Max (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "Encoding_Conv2D_4 (Conv2D)   (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "Encoding_MaxPooling2D_4 (Max (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "Encoding_Conv2D_5 (Conv2D)   (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "Decoding_Conv2D_1 (Conv2D)   (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "Decoding_Upsamping2D_1 (UpSa (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "Decoding_Conv2D_2 (Conv2D)   (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "Decoding_Upsamping2D_2 (UpSa (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "Decoding_Conv2D_3 (Conv2D)   (None, 28, 28, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "Decoding_Upsamping2D_3 (UpSa (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "Decoding_Conv2D_4 (Conv2D)   (None, 56, 56, 128)       295040    \n",
            "_________________________________________________________________\n",
            "Decoding_Upsamping2D_4 (UpSa (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "Decoding_Conv2D_5 (Conv2D)   (None, 112, 112, 64)      73792     \n",
            "_________________________________________________________________\n",
            "Decoding_Upsamping2D_5 (UpSa (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "Decoding_Output (Conv2D)     (None, 224, 224, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 10,180,867\n",
            "Trainable params: 10,180,867\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW9yai_JnedK"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7rXn304nfgN",
        "outputId": "d82c5b7b-d049-4356-a119-e9abf80850c4"
      },
      "source": [
        "optimizer = Adam(learning_rate=0.001) \n",
        "model = encoder_decoder_model() \n",
        "model.compile(optimizer=optimizer, loss='mse') \n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=6,min_delta=0.0001) \n",
        "checkpoint = ModelCheckpoint('encoder_model.h5', monitor='val_loss', mode='min', save_best_only=True) \n",
        "model.fit(train_data, train_data, epochs=35, batch_size=32,validation_data=(test_data,test_data),callbacks=[early_stopping,checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "4/4 [==============================] - 98s 22s/step - loss: 2.0691 - val_loss: 1.5625\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 1.4150 - val_loss: 1.0375\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.9330 - val_loss: 0.6686\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - 92s 21s/step - loss: 0.5990 - val_loss: 0.4309\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.3850 - val_loss: 0.2782\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - 95s 22s/step - loss: 0.2562 - val_loss: 0.1926\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.1827 - val_loss: 0.1456\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.1416 - val_loss: 0.1186\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.1179 - val_loss: 0.1015\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.1021 - val_loss: 0.0905\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.0906 - val_loss: 0.0795\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.0811 - val_loss: 0.0716\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - 96s 21s/step - loss: 0.0735 - val_loss: 0.0662\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.0678 - val_loss: 0.0613\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - 94s 22s/step - loss: 0.0636 - val_loss: 0.0583\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - 95s 22s/step - loss: 0.0608 - val_loss: 0.0564\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - 94s 21s/step - loss: 0.0589 - val_loss: 0.0544\n",
            "Epoch 18/35\n",
            "4/4 [==============================] - 93s 21s/step - loss: 0.0577 - val_loss: 0.0534\n",
            "Epoch 19/35\n",
            "4/4 [==============================] - 97s 23s/step - loss: 0.0567 - val_loss: 0.0524\n",
            "Epoch 20/35\n",
            "4/4 [==============================] - 94s 21s/step - loss: 0.0559 - val_loss: 0.0523\n",
            "Epoch 21/35\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}